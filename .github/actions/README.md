# Hackathon Judge - Automated Code Analysis Workflow

This repository contains a comprehensive automated hackathon judging system that analyzes pull requests and generates detailed reports for teams. The system evaluates code quality, security, testing, frontend usability, team collaboration, and AI usage attribution.

## ğŸ¯ What It Does

### Automated Analysis Pipeline

The workflow automatically runs when:

- **Pull Requests** are opened, synchronized, or reopened
- **Manual Workflow Dispatch** is triggered

### Complete Team Evaluation

For each PR submission, the system:

1. **Extracts Team Information** from PR metadata
2. **Detects Technology Stack** (language, framework, frontend presence)
3. **Installs Dependencies** based on detected stack
4. **Runs Tests & Coverage Analysis**
5. **Performs SonarCloud Code Quality Analysis**
6. **Conducts Security Vulnerability Scanning**
7. **Audits Frontend Usability** (if applicable)
8. **Analyzes Team Collaboration Patterns**
9. **Detects AI Usage Attribution**
10. **Calculates Final Score** with weighted components
11. **Generates Multiple Report Formats**
12. **Commits Reports to Repository**
13. **Creates Dashboard Index Page**
14. **Posts Results as PR Comments**

## ğŸ“Š Reports Generated

### 1. **Team Directory Structure**

```
reports/teams/[TeamName]/pr-[PR-Number]/
â”œâ”€â”€ ai-analysis.json              # AI usage detection results
â”œâ”€â”€ coverage-summary.json         # Test coverage metrics
â”œâ”€â”€ security-summary.json         # Security vulnerability summary
â”œâ”€â”€ team-analysis.json           # Team collaboration analysis
â”œâ”€â”€ trivy-results.json           # Detailed security scan results
â”œâ”€â”€ score-breakdown.json         # Component scores and weights
â”œâ”€â”€ sonar-analysis-results.json  # SonarCloud analysis details
â”œâ”€â”€ analysis-[timestamp].json    # Timestamped analysis metadata
â”œâ”€â”€ latest-summary.md            # Human-readable summary
â””â”€â”€ hackathon-report-[TeamName].html  # Detailed HTML report
```

### 2. **Dashboard Index Page**

- **Location**: `reports/index.html`
- **Features**:
  - Team performance overview cards
  - Statistics grid (total teams, average score, top performer)
  - Direct links to individual team reports
  - Responsive design for mobile/desktop
  - Automatic updates when new reports are added

### 3. **GitHub Actions Artifacts**

- **Name**: `hackathon-analysis-[TeamName]-pr[PR-Number]`
- **Contents**: All JSON reports and analysis files
- **Retention**: 30 days

## ğŸ”§ Environment Variables

### Required Environment Variables

```yaml
env:
  NODE_VERSION: "18" # Node.js version for setup
  JAVA_VERSION: "17" # Java version for SonarCloud
  SONAR_SCANNER_VERSION: "5.0.1.3006" # SonarCloud scanner version
  PYTHON_VERSION: "3.x" # Python version for tools
```

### Required Secrets

- `SONAR_TOKEN`: SonarCloud authentication token
- `GITHUB_TOKEN`: Automatically provided by GitHub Actions

### Required Repository Variables

- `SONAR_PROJECT_KEY`: Your SonarCloud project key
- `SONAR_ORGANIZATION`: Your SonarCloud organization name

### Required Permissions

```yaml
permissions:
  issues: write # To post PR comments
  pull-requests: write # To update PR status
  contents: write # To commit reports to repository
```

## ğŸ“ Repository Structure

```
.github/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ self-contained-hackathon-judge.yml  # Main workflow
â”œâ”€â”€ actions/                                # Modular analysis components
â”‚   â”œâ”€â”€ setup-env/                         # Environment setup
â”‚   â”œâ”€â”€ detect-stack/                      # Technology detection
â”‚   â”œâ”€â”€ install-deps/                      # Dependency installation
â”‚   â”œâ”€â”€ test-coverage/                     # Test execution & coverage
â”‚   â”œâ”€â”€ sonar-analysis/                    # SonarCloud integration
â”‚   â”œâ”€â”€ security-scan/                     # Security vulnerability scanning
â”‚   â”œâ”€â”€ frontend-audit/                    # Lighthouse & UX analysis
â”‚   â”œâ”€â”€ team-behavior/                     # Git history analysis
â”‚   â”œâ”€â”€ ai-detection/                      # AI usage detection
â”‚   â”œâ”€â”€ calculate-score/                   # Score calculation
â”‚   â”œâ”€â”€ generate-html-report/              # HTML report generation
â”‚   â””â”€â”€ post-comment/                      # PR comment posting
â””â”€â”€ scripts/
    â”œâ”€â”€ extract-pr-info.js                 # PR metadata extraction
    â”œâ”€â”€ generate-index.js                  # Dashboard generation
    â””â”€â”€ generate-html-report.js            # HTML report creation
```

## ğŸ“Š Scoring System

| Component              | Weight | Description                                              |
| ---------------------- | ------ | -------------------------------------------------------- |
| **Tests & Coverage**   | 25%    | Unit tests, integration tests, code coverage             |
| **Code Quality**       | 30%    | SonarCloud analysis (bugs, code smells, maintainability) |
| **Security**           | 20%    | Vulnerability scanning, dependency security              |
| **Frontend UX**        | 10%    | Lighthouse scores (performance, accessibility, SEO)      |
| **Team Collaboration** | 10%    | Git history, commit quality, author diversity            |
| **AI Attribution**     | 5%     | Proper attribution of AI-assisted development            |

## ğŸš€ Access Reports

### Team Reports

Individual team reports are accessible at:

```
https://github.com/[owner]/[repo]/tree/main/reports/teams/[TeamName]/pr-[PR-Number]/
```

### Dashboard

The main dashboard is available at:

```
https://github.com/[owner]/[repo]/blob/main/reports/index.html
```

### PR Comments

Each analyzed PR receives an automated comment with:

- Overall score and breakdown
- Links to detailed reports
- Security vulnerability summary
- Code quality metrics
- Dashboard link
